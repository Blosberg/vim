Regression:

= multi-linear regression  Using scikit-learn =
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

  == generate synthetic data, split into training and testing ==

n = 500; beta_0=5; beta_1=2; beta_2=-1
np.random.seed(1)
x_1 = 10* ss.uniform.rvs(size=n)
x_2 = 10* ss.uniform.rvs(size=n)
X=np.stack( [x_1,x_2],
            axis = 1)
y   = beta_0 + beta_1*x_1 + beta_2*x_2 + ss.norm.rvs( loc=0,
                                                      scale=1,
                                                      size=n)

X_train, X_test, y_train, y_test = train_test_split( X, y,
                                                     train_size = 0.5,
                                                     random_state=1)
  == plot in 3d ---------------------------- ==
from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure()
ax  = fig.add_subplot(111,projection="3d")
ax.scatter(X[:,0], X[:,1], y, c=y)
ax.set_xlabel("$x_1$")
ax.set_ylabel("$x_2$")
ax.set_zlabel("$y$")

  == create and fit the model -------------- ==
lm = LinearRegression(fit_intercept=True)
lm.fit(X_train, y_train)

# check out the results:
lm.intercept_
lm.coef_
lm.score(X_test,y_test)

= statsmodels  ----------------------------- =

import statsmodels.api as sm

# Create some synthetic data:
n=100
beta_0 = 5
beta_1 = 2
np.random.seed(1)
x = 10* ss.uniform.rvs(size=n, )
y = beta_0 + beta_1 * x + ss.norm.rvs(loc=0,
                                      scale=1,
                                      size=n)

# Add a column of 1's for constant in reg.
X= sm.add_constant(x)

# create the model, fit the estimate
# and print a summary of the results
mod = sm.OLS(y,X)
est = mod.fit()
print(est.summary())

